# Tensorflow Profiler Diff

Profiling memory with Tensorflow can be tedious, especially when comparing memory usage between different models or batches.
This standalone python script `tfprof_diff.py` allows you to compare the memory usage of different scope files that were generated by the [Tensorflow Profiler tfprof](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler).

Generate a scope file for two models / time steps you want to profile and compare (see below), and run

```shell script
python3 tfprof_diff.py scope_file1 scope_file2 left right --delta 0.1 --min_size 1MB
```

`tfprof_diff.py` will print a file similar to a tfprof scope file showing all nodes that have significant differences in memory or do not appear in all supplied scope files:

```
Comparing scope files scope_file1 (left), scope_file2 (right)
 - Showing nodes with minimum size >= 1MB and relative difference in memory >= 10.0% or such children
 - Showing absolute memory differences memory(left) - memory(right) and relative memory differences memory(left) / memory(right)

_TfProfRoot (left:6220MB right:2840MB) +3380MB x2.2
  optimize (left:4640MB right:1820MB) +2820MB x2.5
    optimize/gradients (left:4210MB right:1390MB) +2820MB x3.0
      optimize/gradients/output (left:2760MB right:595MB) +2160MB x4.6
        optimize/gradients/output/rec (left:2760MB right:595MB) +2160MB x4.6
          optimize/gradients/output/rec/output_prob (left:432MB right:40.3MB) +392MB x10.7
            optimize/gradients/output/rec/output_prob/linear (left:432MB right:40.3MB) +392MB x10.7
              optimize/gradients/output/rec/output_prob/linear/dot (left:431MB right:40.1MB) +391MB x10.7
                optimize/gradients/output/rec/output_prob/linear/dot/MatMul_grad (left:431MB right:40.1MB) +391MB x10.7
                  optimize/gradients/output/rec/output_prob/linear/dot/MatMul_grad/MatMul_1 (left:430MB right:39.1MB) +391MB x11.0
          optimize/gradients/output/rec/while_loop_body (left:353MB) +353MB 
            optimize/gradients/output/rec/while_loop_body/loss (left:353MB) +353MB 
              optimize/gradients/output/rec/while_loop_body/loss/loss_ce (left:353MB) +353MB 
...
```

Tip: Change the names `left` and `right` to meaningful names of your models / steps.

## Generating scope files

To create a scope file loaded by `tfprof_diff.py`, Generate a GraphDef file `graphpb.txt` for every model, and a RunMetadata proto file for every step to profile.
For more on this, see the [tfprof documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/command_line.md). For example, add this to your tensorflow code:
```python
# once per model
tf.get_default_graph().as_graph_def(add_shapes=True)

# once every step to profile (note: this takes some time, do this only every other step)
run_options = config_pb2.RunOptions(trace_level=config_pb2.RunOptions.FULL_TRACE)
run_metadata = tf.RunMetadata()
_ = sess.run(..., run_options=run_options, run_metadata=run_metadata)

run_meta_path = os.path.join(logdir, 'run_meta_%s' % step)
with gfile.Open(run_meta_path, 'w') as f:
  f.write(run_metadata.SerializeToString())
```

Then, install the Tensorflow Profiler and generate a scope file for every step to profile as follows:

```shell script
tfprof scope --graph_path=graph.pbtxt --run_meta_path=run_meta_STEP --select=bytes --min_bytes=1 > scope_file
```

Here, the minimum node size is set to `1` (= 1B), as `tfprof_diff.py` will filter small graph nodes afterwards.
The file will look as follows:

```
Reading Files...
Try to use a single --profile_path instead of graph_path,op_log_path,run_meta_path
Parsing Inputs...
run graph coverage: 0.32

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
requested bytes: The memory requested by the operation, accumulatively.

Profile:
node name | requested bytes
_TFProfRoot (--/2844.73MB)
  Merge (0B/32B)
    Merge/MergeSummary (32B/32B)
  dec_01_att_key (0B/1.06KB)
    dec_01_att_key/Reshape (0B/16B)
...
```
